"""
ASTè§£æå™¨
è´Ÿè´£æŠ½è±¡è¯­æ³•æ ‘ï¼ˆASTï¼‰çš„ç”Ÿæˆå’Œåˆ†æ
"""

import logging
import os
from typing import Any, Dict, List, Optional, Set, Callable
from langchain_core.documents import Document
from tree_sitter import Language, Parser, Node

# åŠ¨æ€å¯¼å…¥è¯­è¨€è§£æå™¨
AVAILABLE_PARSERS = {}

# è¯­è¨€æ¨¡å—æ˜ å°„
LANGUAGE_MODULES = {
    'python': 'tree_sitter_python',
    'javascript': 'tree_sitter_javascript',
    'typescript': 'tree_sitter_typescript', 
    'java': 'tree_sitter_java',
    'cpp': 'tree_sitter_cpp',
    'go': 'tree_sitter_go',
    'rust': 'tree_sitter_rust',
    'csharp': 'tree_sitter_c_sharp'
}

# åŠ¨æ€åŠ è½½å¯é€‰è¯­è¨€è§£æå™¨
for lang, module_name in LANGUAGE_MODULES.items():
    try:
        module = __import__(module_name, fromlist=[module_name])
        AVAILABLE_PARSERS[lang] = module
    except ImportError:
        pass

# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ æ›´å¥½çš„å¯¼å…¥å¤„ç†
try:
    from .file_parser import FileType
    from ..core.config import settings
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶çš„å›é€€
    class FileType:
        CODE = "code"
        TEXT = "text"
        BINARY = "binary"
    
    class Settings:
        AST_MAX_FILE_SIZE = 1024 * 1024
        AST_SUPPORTED_LANGUAGES = []
    
    settings = Settings()

logger = logging.getLogger(__name__)

class AstParser:
    # è¯­è¨€é…ç½®ç¼“å­˜
    _LANGUAGE_CONFIGS = {
        'python': {'extensions': {'.py'}, 'node_types': {
            'class_definition', 'function_definition', 'assignment', 
            'decorated_definition', 'import_statement', 'import_from_statement'
        }},
        'javascript': {'extensions': {'.js', '.jsx', '.mjs'}, 'node_types': {
            'class_declaration', 'function_declaration', 'method_definition',
            'arrow_function', 'variable_declaration', 'import_statement', 'export_statement'
        }},
        'typescript': {'extensions': {'.ts', '.tsx'}, 'node_types': {
            'class_declaration', 'function_declaration', 'method_definition',
            'arrow_function', 'variable_declaration', 'import_statement', 'export_statement'
        }},
        'java': {'extensions': {'.java'}, 'node_types': {
            'class_declaration', 'interface_declaration', 'method_declaration',
            'field_declaration', 'import_declaration', 'package_declaration'
        }},
        'cpp': {'extensions': {'.cpp', '.cc', '.cxx', '.c++', '.hpp', '.h'}, 'node_types': {
            'class_specifier', 'struct_specifier', 'function_definition',
            'declaration', 'preproc_include'
        }},
        'go': {'extensions': {'.go'}, 'node_types': {
            'type_declaration', 'function_declaration', 'method_declaration',
            'var_declaration', 'import_declaration', 'package_clause'
        }},
        'rust': {'extensions': {'.rs'}, 'node_types': {
            'struct_item', 'enum_item', 'impl_item', 'function_item',
            'let_declaration', 'use_declaration'
        }},
        'csharp': {'extensions': {'.cs'}, 'node_types': {
            'class_declaration', 'interface_declaration', 'struct_declaration',
            'method_declaration', 'property_declaration', 'field_declaration', 'using_directive'
        }}
    }

    def __init__(self):
        """åˆå§‹åŒ–ASTè§£æå™¨"""
        self.parsers: Dict[str, Parser] = {}
        self._extension_to_language = {}
        self._element_extractors_cache = {}
        self._init_languages()

    def _init_languages(self):
        """åˆå§‹åŒ–æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€"""
        initialized_count = 0
        
        for lang_name, config in self._LANGUAGE_CONFIGS.items():
            if lang_name not in AVAILABLE_PARSERS:
                logger.debug(f"âš ï¸ {lang_name} è§£æå™¨æ¨¡å—æœªå®‰è£…ï¼Œè·³è¿‡åˆå§‹åŒ–")
                continue
                
            try:
                module = AVAILABLE_PARSERS[lang_name]
                
                # è·å–è¯­è¨€å¯¹è±¡
                language = None

                if lang_name == 'typescript' and hasattr(module, 'language_typescript'):
                    language = Language(module.language_typescript())
                elif lang_name == 'typescript' and hasattr(module, 'typescript'):
                    language = Language(module.typescript())
                else:
                    language = Language(module.language())

                parser = Parser(language)
                
                self.parsers[lang_name] = parser
                
                # æ„å»ºæ‰©å±•åæ˜ å°„
                for ext in config['extensions']:
                    self._extension_to_language[ext] = lang_name
                
                initialized_count += 1
                logger.debug(f"âœ… åˆå§‹åŒ– {lang_name} è§£æå™¨æˆåŠŸ")
                
            except Exception as e:
                logger.warning(f"âš ï¸ åˆå§‹åŒ– {lang_name} è§£æå™¨å¤±è´¥: {e}")

        logger.info(f"ğŸ”§ ASTè§£æå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒ {initialized_count} ç§è¯­è¨€: {list(self.parsers.keys())}")

    def _detect_language_from_extension(self, file_path: str) -> Optional[str]:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åæ£€æµ‹ç¼–ç¨‹è¯­è¨€"""
        ext = os.path.splitext(file_path)[1].lower()
        return self._extension_to_language.get(ext)

    def should_use_ast_parsing(self, file_info: Dict[str, Any], language: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨ASTè§£æ
        
        Args:
            file_info: æ–‡ä»¶ä¿¡æ¯
            language: ç¼–ç¨‹è¯­è¨€
            
        Returns:
            bool: æ˜¯å¦ä½¿ç”¨ASTè§£æ
        """
        # åªå¯¹ä»£ç æ–‡ä»¶ä½¿ç”¨ASTè§£æ
        if file_info.get("file_type") != FileType.CODE:
            return False
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
        max_size = getattr(settings, 'AST_MAX_FILE_SIZE', 1024 * 1024)  # 1MB
        if file_info.get("file_size", 0) > max_size:
            logger.debug(f"âš ï¸ æ–‡ä»¶è¿‡å¤§ï¼Œè·³è¿‡ASTè§£æ: {file_info.get('file_path')}")
            return False
        
        # æ£€æŸ¥è¯­è¨€æ”¯æŒ
        detected_lang = self._detect_language_from_extension(file_info.get('file_path', ''))
        return (detected_lang in self.parsers or 
                language.lower() in self.parsers)

    def parse_with_ast(self, content: str, file_path: str, language: str) -> List[Document]:
        """
        ä½¿ç”¨ASTè§£ææ–‡ä»¶å†…å®¹

        Args:
            content: æ–‡ä»¶å†…å®¹
            file_path: æ–‡ä»¶è·¯å¾„
            language: ç¼–ç¨‹è¯­è¨€

        Returns:
            List[Document]: è§£æå¾—åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        # ç¡®å®šå®é™…ä½¿ç”¨çš„è¯­è¨€
        actual_language = self._determine_language(file_path, language)
        if not actual_language:
            return self._create_fallback_document(content, file_path, language, "unsupported_language")

        try:
            # ä½¿ç”¨å¯¹åº”è¯­è¨€çš„è§£æå™¨
            parser = self.parsers[actual_language]
            tree = parser.parse(content.encode('utf8'))
            
            if tree.root_node.has_error:
                logger.warning(f"âš ï¸ ASTåŒ…å«è¯­æ³•é”™è¯¯: {file_path}")
            
            documents = []
            source_bytes = content.encode('utf8')
            
            # æå–ä»£ç å…ƒç´ 
            self._extract_code_elements(tree.root_node, source_bytes, file_path, documents, actual_language)
            
            logger.debug(f"âœ… ASTè§£æå®Œæˆ: {file_path} ({actual_language}), æå–äº† {len(documents)} ä¸ªä»£ç å…ƒç´ ")
            return documents
            
        except Exception as e:
            logger.error(f"âŒ ASTè§£æå¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
            return self._create_fallback_document(content, file_path, language, "ast_parsing_failed")

    def _determine_language(self, file_path: str, language: str) -> Optional[str]:
        """ç¡®å®šè¦ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€"""
        # ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶æ‰©å±•åæ£€æµ‹
        detected_lang = self._detect_language_from_extension(file_path)
        if detected_lang and detected_lang in self.parsers:
            return detected_lang
        
        # å…¶æ¬¡ä½¿ç”¨ä¼ å…¥çš„è¯­è¨€å‚æ•°
        normalized_lang = language.lower()
        if normalized_lang in self.parsers:
            return normalized_lang
            
        return None

    def _create_fallback_document(self, content: str, file_path: str, language: str, error_type: str) -> List[Document]:
        """åˆ›å»ºå›é€€æ–‡æ¡£"""
        if error_type == "unsupported_language":
            logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„è¯­è¨€: {language}, æ–‡ä»¶: {file_path}")
        
        return [Document(
            page_content=content,
            metadata={
                "file_path": file_path,
                "language": language,
                "element_type": "file",
                error_type: True
            }
        )]

    def _extract_code_elements(self, node: Node, source_bytes: bytes, file_path: str, 
                             documents: List[Document], language: str):
        """
        é€’å½’æå–ä»£ç å…ƒç´ 
        
        Args:
            node: ASTèŠ‚ç‚¹
            source_bytes: æºä»£ç å­—èŠ‚
            file_path: æ–‡ä»¶è·¯å¾„
            documents: æ–‡æ¡£åˆ—è¡¨
            language: ç¼–ç¨‹è¯­è¨€
        """
        # è·å–å…ƒç´ æå–å™¨ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        extractors = self._get_element_extractors_cached(language)
        
        # å¦‚æœå½“å‰èŠ‚ç‚¹æ˜¯ç›®æ ‡ç±»å‹ï¼Œæå–å®ƒ
        if node.type in extractors:
            try:
                doc = extractors[node.type](node, source_bytes, file_path, language)
                if doc:
                    documents.append(doc)
            except Exception as e:
                logger.warning(f"âš ï¸ æå–èŠ‚ç‚¹å¤±è´¥: {node.type} in {file_path}, é”™è¯¯: {str(e)}")
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            self._extract_code_elements(child, source_bytes, file_path, documents, language)

    def _get_element_extractors_cached(self, language: str) -> Dict[str, Callable]:
        """è·å–å…ƒç´ æå–å™¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if language not in self._element_extractors_cache:
            self._element_extractors_cache[language] = self._build_element_extractors(language)
        return self._element_extractors_cache[language]

    def _build_element_extractors(self, language: str) -> Dict[str, Callable]:
        """æ„å»ºå…ƒç´ æå–å™¨æ˜ å°„"""
        # åŸºç¡€æå–å™¨
        extractors = {}
        
        # æ ¹æ®è¯­è¨€é…ç½®æ·»åŠ æå–å™¨
        config = self._LANGUAGE_CONFIGS.get(language, {})
        node_types = config.get('node_types', set())
        
        for node_type in node_types:
            if 'class' in node_type or 'struct' in node_type or 'interface' in node_type or 'enum' in node_type:
                extractors[node_type] = self._extract_class
            elif 'function' in node_type or 'method' in node_type:
                extractors[node_type] = self._extract_function
            elif 'import' in node_type or 'export' in node_type or 'package' in node_type or 'using' in node_type or 'use_declaration' in node_type:
                extractors[node_type] = self._extract_import
            elif 'assignment' in node_type or 'declaration' in node_type or 'var_' in node_type or 'let_' in node_type or 'field_' in node_type or 'property_' in node_type:
                extractors[node_type] = self._extract_assignment
            elif 'decorated' in node_type:
                extractors[node_type] = self._extract_decorated_definition
                
        return extractors

    def _extract_class(self, node: Node, source_bytes: bytes, file_path: str, language: str = "python") -> Document:
        """æå–ç±»å®šä¹‰"""
        content = source_bytes[node.start_byte:node.end_byte].decode('utf8')
        
        # æå–ç±»å - æ ¹æ®è¯­è¨€è°ƒæ•´
        class_name = self._extract_identifier(node, source_bytes, language)
        
        return Document(
            page_content=content,
            metadata={
                "file_path": file_path,
                "element_type": "class",
                "element_name": class_name,
                "start_line": node.start_point[0] + 1,
                "end_line": node.end_point[0] + 1,
                "language": language
            }
        )

    def _extract_function(self, node: Node, source_bytes: bytes, file_path: str, language: str = "python") -> Document:
        """æå–å‡½æ•°å®šä¹‰"""
        content = source_bytes[node.start_byte:node.end_byte].decode('utf8')
        
        # æå–å‡½æ•°å
        function_name = self._extract_identifier(node, source_bytes, language)
        
        return Document(
            page_content=content,
            metadata={
                "file_path": file_path,
                "element_type": "function",
                "element_name": function_name,
                "start_line": node.start_point[0] + 1,
                "end_line": node.end_point[0] + 1,
                "language": language
            }
        )

    def _extract_import(self, node: Node, source_bytes: bytes, file_path: str, language: str = "python") -> Document:
        """æå–å¯¼å…¥è¯­å¥"""
        content = source_bytes[node.start_byte:node.end_byte].decode('utf8')
        
        return Document(
            page_content=content,
            metadata={
                "file_path": file_path,
                "element_type": "import",
                "element_name": content.strip(),
                "start_line": node.start_point[0] + 1,
                "end_line": node.end_point[0] + 1,
                "language": language
            }
        )

    def _extract_assignment(self, node: Node, source_bytes: bytes, file_path: str, language: str = "python") -> Document:
        """æå–å˜é‡èµ‹å€¼"""
        content = source_bytes[node.start_byte:node.end_byte].decode('utf8')
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡å—çº§åˆ«çš„èµ‹å€¼
        if language == 'python':
            parent = node.parent
            while parent:
                if parent.type in ['function_definition', 'class_definition']:
                    return None
                parent = parent.parent
        
        # æå–å˜é‡å
        variable_name = self._extract_variable_name(node, source_bytes, language)
        
        return Document(
            page_content=content,
            metadata={
                "file_path": file_path,
                "element_type": "assignment",
                "element_name": variable_name,
                "start_line": node.start_point[0] + 1,
                "end_line": node.end_point[0] + 1,
                "language": language
            }
        )

    def _extract_decorated_definition(self, node: Node, source_bytes: bytes, file_path: str, language: str = "python") -> Document:
        """æå–è£…é¥°å™¨å®šä¹‰"""
        content = source_bytes[node.start_byte:node.end_byte].decode('utf8')
        
        # æŸ¥æ‰¾è¢«è£…é¥°çš„å®šä¹‰
        definition_name = self._extract_identifier(node, source_bytes, language)
        
        return Document(
            page_content=content,
            metadata={
                "file_path": file_path,
                "element_type": "decorated_definition",
                "element_name": definition_name,
                "start_line": node.start_point[0] + 1,
                "end_line": node.end_point[0] + 1,
                "language": language
            }
        )

    def _extract_identifier(self, node: Node, source_bytes: bytes, language: str) -> str:
        """æå–æ ‡è¯†ç¬¦åç§°"""
        # è¯­è¨€ç‰¹å®šçš„æ ‡è¯†ç¬¦æå–ç­–ç•¥
        if language == 'javascript' or language == 'typescript':
            return self._extract_js_identifier(node, source_bytes)
        elif language == 'java':
            return self._extract_java_identifier(node, source_bytes)
        elif language == 'python':
            return self._extract_python_identifier(node, source_bytes)
        else:
            # é€šç”¨æå–é€»è¾‘
            return self._extract_generic_identifier(node, source_bytes)

    def _extract_js_identifier(self, node: Node, source_bytes: bytes) -> str:
        """æå–JavaScript/TypeScriptæ ‡è¯†ç¬¦"""
        # JavaScriptæ–¹æ³•å®šä¹‰çš„ç‰¹æ®Šå¤„ç†
        if node.type == 'method_definition':
            # æŸ¥æ‰¾property_identifierèŠ‚ç‚¹
            for child in node.children:
                if child.type == 'property_identifier':
                    return source_bytes[child.start_byte:child.end_byte].decode('utf8')
        
        # å‡½æ•°å£°æ˜å’Œç®­å¤´å‡½æ•°
        if node.type in ['function_declaration', 'arrow_function']:
            for child in node.children:
                if child.type == 'identifier':
                    return source_bytes[child.start_byte:child.end_byte].decode('utf8')
        
        # å˜é‡å£°æ˜
        if node.type == 'variable_declaration':
            for child in node.children:
                if child.type == 'variable_declarator':
                    for grandchild in child.children:
                        if grandchild.type == 'identifier':
                            return source_bytes[grandchild.start_byte:grandchild.end_byte].decode('utf8')
        
        # é€šç”¨æŸ¥æ‰¾
        return self._extract_generic_identifier(node, source_bytes)

    def _extract_python_identifier(self, node: Node, source_bytes: bytes) -> str:
        """æå–Pythonæ ‡è¯†ç¬¦"""
        # ç›´æ¥æŸ¥æ‰¾identifierèŠ‚ç‚¹
        for child in node.children:
            if child.type == "identifier":
                return source_bytes[child.start_byte:child.end_byte].decode('utf8')
        
        # é€’å½’æŸ¥æ‰¾
        return self._extract_identifier_recursive(node, source_bytes, max_depth=2)

    def _extract_java_identifier(self, node: Node, source_bytes: bytes) -> str:
        """æå–Javaæ ‡è¯†ç¬¦"""
        # Javaç‰¹å®šçš„æ ‡è¯†ç¬¦æå–
        for child in node.children:
            if child.type == "identifier":
                return source_bytes[child.start_byte:child.end_byte].decode('utf8')
        
        return self._extract_generic_identifier(node, source_bytes)

    def _extract_generic_identifier(self, node: Node, source_bytes: bytes) -> str:
        """é€šç”¨æ ‡è¯†ç¬¦æå–"""
        # ç›´æ¥æŸ¥æ‰¾identifierèŠ‚ç‚¹
        for child in node.children:
            if child.type == "identifier":
                return source_bytes[child.start_byte:child.end_byte].decode('utf8')
        
        # é€’å½’æŸ¥æ‰¾ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
        return self._extract_identifier_recursive(node, source_bytes, max_depth=3)

    def _extract_identifier_recursive(self, node: Node, source_bytes: bytes, max_depth: int = 2) -> str:
        """é€’å½’æå–æ ‡è¯†ç¬¦ï¼ˆé™åˆ¶æ·±åº¦ï¼‰"""
        if max_depth <= 0:
            return "Unknown"
            
        for child in node.children:
            if child.type in ["identifier", "property_identifier"]:
                return source_bytes[child.start_byte:child.end_byte].decode('utf8')
            
            # é€’å½’æŸ¥æ‰¾
            result = self._extract_identifier_recursive(child, source_bytes, max_depth - 1)
            if result != "Unknown":
                return result
        
        return "Unknown"

    def _extract_variable_name(self, node: Node, source_bytes: bytes, language: str) -> str:
        """æå–å˜é‡å"""
        # å¿«é€Ÿè·¯å¾„ï¼šPythonç®€å•èµ‹å€¼
        if language == 'python':
            content = source_bytes[node.start_byte:node.end_byte].decode('utf8')
            if '=' in content:
                return content.split('=')[0].strip()
        
        # é€šç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾variable_declaratoræˆ–identifier
        for child in node.children:
            if child.type == 'variable_declarator':
                identifier = self._extract_identifier(child, source_bytes, language)
                if identifier != "Unknown":
                    return identifier
            elif child.type == 'identifier':
                return source_bytes[child.start_byte:child.end_byte].decode('utf8')
        
        return "Unknown"

    def get_supported_languages(self) -> List[str]:
        """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        return list(self.parsers.keys())

    def get_language_extensions(self, language: str) -> Set[str]:
        """è·å–è¯­è¨€æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å"""
        config = self._LANGUAGE_CONFIGS.get(language, {})
        return config.get('extensions', set())
