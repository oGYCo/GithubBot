"""
æŸ¥è¯¢æœåŠ¡ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜
å®ç°æ··åˆæ£€ç´¢ï¼ˆå‘é‡æ£€ç´¢ + BM25 å…³é”®è¯æ£€ç´¢ï¼‰å’Œé‡æ’åº
ç„¶åæ ¹æ®æ£€ç´¢åˆ°çš„æ–‡æœ¬å¿«å—ç”Ÿæˆç›¸åº”çš„å›ç­”
"""

import time
import logging
import re
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from sqlalchemy.orm import Session
from rank_bm25 import BM25Okapi

from ..core.config import settings
from ..db.session import get_db_session
from ..db.models import AnalysisSession, QueryLog, TaskStatus, Repository
from ..utils.git_helper import GitHelper
from ..services.embedding_manager import EmbeddingManager, EmbeddingConfig
from ..services.llm_manager import LLMManager, LLMConfig
from ..services.vector_store import get_vector_store
from ..schemas.repository import (
    QueryRequest, QueryResponse, RetrievedChunk,
    GenerationMode, LLMConfig as LLMConfigSchema
)

logger = logging.getLogger(__name__)


class QueryService:
    """æŸ¥è¯¢æœåŠ¡"""

    def __init__(self):
        self._bm25_cache = {}  # ç¼“å­˜ BM25 ç´¢å¼•
        self._documents_cache = {}  # ç¼“å­˜æ–‡æ¡£å†…å®¹
        self.git_helper = GitHelper()  # GitåŠ©æ‰‹å®ä¾‹
    
    def clear_cache(self, identifier: str = None):
        """
        æ¸…é™¤BM25ç¼“å­˜
        
        Args:
            identifier: æŒ‡å®šä¼šè¯IDæˆ–ä»“åº“æ ‡è¯†ç¬¦ï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        """
        if identifier:
            self._bm25_cache.pop(identifier, None)
            self._documents_cache.pop(identifier, None)
            logger.info(f"ğŸ§¹ [ç¼“å­˜æ¸…é™¤] å·²æ¸…é™¤æ ‡è¯†ç¬¦ {identifier} çš„BM25ç¼“å­˜")
        else:
            self._bm25_cache.clear()
            self._documents_cache.clear()
            logger.info(f"ğŸ§¹ [ç¼“å­˜æ¸…é™¤] å·²æ¸…é™¤æ‰€æœ‰BM25ç¼“å­˜")

    def query(self, request: QueryRequest) -> QueryResponse:
        """
        å¤„ç†æŸ¥è¯¢è¯·æ±‚

        Args:
            request: æŸ¥è¯¢è¯·æ±‚

        Returns:
            QueryResponse: æŸ¥è¯¢å“åº”
        """
        start_time = time.time()
        db = get_db_session()

        try:
            # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
            logger.info(f"ğŸ” [DEBUG] QueryRequest å¯¹è±¡ç±»å‹å’Œå†…å®¹:")
            logger.info(f"ğŸ” [DEBUG] - session_id: {request.session_id} (type: {type(request.session_id)})")
            logger.info(f"ğŸ” [DEBUG] - question: {request.question[:50]}... (type: {type(request.question)})")
            logger.info(f"ğŸ” [DEBUG] - generation_mode: {request.generation_mode} (type: {type(request.generation_mode)})")
            logger.info(f"ğŸ” [DEBUG] - llm_config: {request.llm_config} (type: {type(request.llm_config)})")
            
            if request.llm_config:
                logger.info(f"ğŸ” [DEBUG] LLMConfig è¯¦ç»†ä¿¡æ¯:")
                logger.info(f"ğŸ” [DEBUG] - provider: {request.llm_config.provider} (type: {type(request.llm_config.provider)})")
                logger.info(f"ğŸ” [DEBUG] - model_name: {request.llm_config.model_name} (type: {type(request.llm_config.model_name)})")
                if hasattr(request.llm_config.provider, 'value'):
                    logger.info(f"ğŸ” [DEBUG] - provider.value: {request.llm_config.provider.value}")
                else:
                    logger.info(f"ğŸ” [DEBUG] - provider æ²¡æœ‰ .value å±æ€§")
            
            # éªŒè¯ä¼šè¯æˆ–ä»“åº“
            validation_result = self._validate_session_or_repository(db, request.session_id)
            if not validation_result:
                return QueryResponse(
                    answer="ä¼šè¯ä¸å­˜åœ¨æˆ–åˆ†ææœªå®Œæˆï¼Œæˆ–è€…ä»“åº“URLæ— æ•ˆ",
                    generation_mode=request.generation_mode
                )
            
            session, repository_identifier = validation_result

            logger.info(f"ğŸš€ [æŸ¥è¯¢å¼€å§‹] ä»“åº“: {repository_identifier} - é—®é¢˜: {request.question[:100]}{'...' if len(request.question) > 100 else ''}")
            logger.info(f"âš™ï¸ [æŸ¥è¯¢é…ç½®] ä»“åº“: {repository_identifier} - ç”Ÿæˆæ¨¡å¼: {request.generation_mode}")
            
            # æ‰§è¡Œæ··åˆæ£€ç´¢
            logger.info(f"ğŸ” [æ£€ç´¢é˜¶æ®µ] ä»“åº“: {repository_identifier} - å¼€å§‹æ‰§è¡Œæ··åˆæ£€ç´¢")
            retrieval_start = time.time()
            retrieved_chunks = self._hybrid_retrieval(
                repository_identifier,
                session.embedding_config,
                request.question
            )
            retrieval_time = int((time.time() - retrieval_start) * 1000)
            logger.info(f"âœ… [æ£€ç´¢å®Œæˆ] ä»“åº“: {repository_identifier} - æ£€ç´¢è€—æ—¶: {retrieval_time}ms, è·å¾— {len(retrieved_chunks)} ä¸ªä¸Šä¸‹æ–‡")

            # å‡†å¤‡å“åº”
            response = QueryResponse(
                retrieved_context=retrieved_chunks,
                generation_mode=request.generation_mode,
                retrieval_time=retrieval_time
            )

            # æ ¹æ®ç”Ÿæˆæ¨¡å¼å¤„ç†
            if request.generation_mode == "service" and request.llm_config:
                # æœåŠ¡ç«¯ç”Ÿæˆç­”æ¡ˆ
                logger.info(f"ğŸ¤– [ç”Ÿæˆé˜¶æ®µ] ä»“åº“: {repository_identifier} - å¼€å§‹ä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆ")
                generation_start = time.time()
                answer = self._generate_answer(
                    request.question,
                    retrieved_chunks,
                    request.llm_config
                )
                generation_time = int((time.time() - generation_start) * 1000)
                logger.info(f"âœ… [ç”Ÿæˆå®Œæˆ] ä»“åº“: {repository_identifier} - ç”Ÿæˆè€—æ—¶: {generation_time}ms, ç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")

                response.answer = answer
                response.generation_time = generation_time
            else:
                logger.info(f"ğŸ“¤ [æ’ä»¶æ¨¡å¼] ä»“åº“: {repository_identifier} - ä»…è¿”å›æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œä¸ç”Ÿæˆç­”æ¡ˆ")

            response.total_time = int((time.time() - start_time) * 1000)
            logger.info(f"ğŸ‰ [æŸ¥è¯¢å®Œæˆ] ä»“åº“: {repository_identifier} - æ€»è€—æ—¶: {response.total_time}ms")

            # è®°å½•æŸ¥è¯¢æ—¥å¿—
            self._log_query(
                db, request, response, retrieved_chunks
            )

            return response

        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            return QueryResponse(
                answer=f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}",
                generation_mode=request.generation_mode,
                total_time=int((time.time() - start_time) * 1000)
            )

        finally:
            if db:
                db.close()

    def _validate_session_or_repository(self, db: Session, session_id: str) -> Optional[Tuple[AnalysisSession, str]]:
        """
        éªŒè¯ä¼šè¯æˆ–ä»“åº“URLï¼Œæ”¯æŒæ™ºèƒ½è¯†åˆ«

        Args:
            db: æ•°æ®åº“ä¼šè¯
            session_id: ä¼šè¯IDæˆ–ä»“åº“URL

        Returns:
            Optional[Tuple[AnalysisSession, str]]: (ä¼šè¯å¯¹è±¡, ä»“åº“æ ‡è¯†ç¬¦) æˆ– None
        """
        # é¦–å…ˆå°è¯•æŒ‰ä¼šè¯IDæŸ¥æ‰¾
        session = db.query(AnalysisSession).filter(
            AnalysisSession.session_id == session_id
        ).first()
        
        if session and session.status == TaskStatus.SUCCESS:
            # ç”Ÿæˆä»“åº“æ ‡è¯†ç¬¦
            repo_identifier = self.git_helper.generate_repository_identifier(session.repository_url)
            logger.info(f"âœ… [ä¼šè¯éªŒè¯] æ‰¾åˆ°æœ‰æ•ˆä¼šè¯: {session_id} -> ä»“åº“: {repo_identifier}")
            return session, repo_identifier

        # å°è¯•å°†è¾“å…¥ä½œä¸ºä»“åº“URLå¤„ç†
        if self._is_likely_repository_url(session_id):
            repo_identifier = self.git_helper.generate_repository_identifier(session_id)
            logger.info(f"ğŸ” [ä»“åº“URLè¯†åˆ«] è¾“å…¥è¯†åˆ«ä¸ºä»“åº“URL: {session_id} -> æ ‡è¯†ç¬¦: {repo_identifier}")
            
            # æŸ¥æ‰¾åŸºäºä»“åº“æ ‡è¯†ç¬¦çš„ä»»ä½•æˆåŠŸä¼šè¯
            session = db.query(AnalysisSession).filter(
                AnalysisSession.repository_identifier == repo_identifier,
                AnalysisSession.status == TaskStatus.SUCCESS
            ).first()
            
            if session:
                logger.info(f"âœ… [ä»“åº“åŒ¹é…] æ‰¾åˆ°åŸºäºä»“åº“çš„æœ‰æ•ˆä¼šè¯: {session.session_id}")
                return session, repo_identifier
            else:
                logger.warning(f"âš ï¸ [ä»“åº“æœªåˆ†æ] ä»“åº“ {session_id} å°šæœªæˆåŠŸåˆ†æ")
                return None

        # éƒ½ä¸åŒ¹é…
        logger.warning(f"âš ï¸ [éªŒè¯å¤±è´¥] æ— æ³•éªŒè¯è¾“å…¥: {session_id}")
        return None

    def _is_likely_repository_url(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦å¯èƒ½æ˜¯ä»“åº“URL
        
        Args:
            text: å¾…æ£€æŸ¥çš„æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦å¯èƒ½æ˜¯ä»“åº“URL
        """
        # ç®€å•çš„URLæ¨¡å¼åŒ¹é…
        url_patterns = [
            r'^https?://github\.com/.+/.+',
            r'^github\.com/.+/.+',
            r'^.+/.+\.git$'
        ]
        
        for pattern in url_patterns:
            if re.match(pattern, text):
                return True
        return False

    def _validate_session(self, db: Session, session_id: str) -> Optional[AnalysisSession]:
        """
        éªŒè¯ä¼šè¯çŠ¶æ€

        Args:
            db: æ•°æ®åº“ä¼šè¯
            session_id: ä¼šè¯ ID

        Returns:
            Optional[AnalysisSession]: ä¼šè¯å¯¹è±¡æˆ– None
        """
        session = db.query(AnalysisSession).filter(
            AnalysisSession.session_id == session_id
        ).first()

        if not session:
            logger.warning(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
            return None

        if session.status != TaskStatus.SUCCESS:
            logger.warning(f"ä¼šè¯åˆ†ææœªå®Œæˆ: {session_id}, çŠ¶æ€: {session.status}")
            return None

        return session

    def _hybrid_retrieval(
            self,
            repository_identifier: str,
            embedding_config: Dict[str, Any],
            question: str
    ) -> List[RetrievedChunk]:
        """
        æ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + BM25 å…³é”®è¯æ£€ç´¢

        Args:
            repository_identifier: ä»“åº“æ ‡è¯†ç¬¦ï¼ˆç”¨äºCollectionå‘½åï¼‰
            embedding_config: Embedding é…ç½®
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            List[RetrievedChunk]: æ£€ç´¢ç»“æœ
        """
        logger.info(f"ğŸ” [æ··åˆæ£€ç´¢å¼€å§‹] ä»“åº“: {repository_identifier} - å¼€å§‹æ‰§è¡Œæ··åˆæ£€ç´¢ç­–ç•¥")
        
        # 1. å‘é‡æ£€ç´¢
        logger.info(f"ğŸ“Š [æ­¥éª¤1/4] ä»“åº“: {repository_identifier} - æ‰§è¡Œå‘é‡æ£€ç´¢")
        vector_results = self._vector_search(repository_identifier, embedding_config, question)

        # 2. BM25 å…³é”®è¯æ£€ç´¢
        logger.info(f"ğŸ“Š [æ­¥éª¤2/4] ä»“åº“: {repository_identifier} - æ‰§è¡ŒBM25å…³é”®è¯æ£€ç´¢")
        bm25_results = self._bm25_search(repository_identifier, question)

        # 3. RRF èåˆ
        logger.info(f"ğŸ“Š [æ­¥éª¤3/4] ä»“åº“: {repository_identifier} - æ‰§è¡ŒRRFèåˆç®—æ³•")
        final_results = self._reciprocal_rank_fusion(vector_results, bm25_results)

        # 4. å–å‰ N ä¸ªç»“æœ
        logger.info(f"ğŸ“Š [æ­¥éª¤4/4] ä»“åº“: {repository_identifier} - ç­›é€‰æœ€ç»ˆç»“æœ")
        top_results = final_results[:settings.FINAL_CONTEXT_TOP_K]
        
        logger.info(f"âœ… [æ··åˆæ£€ç´¢å®Œæˆ] ä»“åº“: {repository_identifier} - æœ€ç»ˆè¿”å› {len(top_results)} ä¸ªä¸Šä¸‹æ–‡å—")
        
        # è®°å½•æœ€ç»ˆç»“æœçš„ç»Ÿè®¡ä¿¡æ¯
        if top_results:
            total_chars = sum(len(chunk.content) for chunk in top_results)
            avg_score = sum(chunk.score for chunk in top_results) / len(top_results)
            logger.info(f"ğŸ“ˆ [ç»“æœç»Ÿè®¡] ä»“åº“: {repository_identifier} - æ€»å­—ç¬¦æ•°: {total_chars}, å¹³å‡åˆ†æ•°: {avg_score:.4f}")
        
        return top_results

    def _vector_search(
            self,
            repository_identifier: str,
            embedding_config: Dict[str, Any],
            question: str
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        å‘é‡æ£€ç´¢

        Args:
            repository_identifier: ä»“åº“æ ‡è¯†ç¬¦
            embedding_config: Embedding é…ç½®
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            List[Tuple[str, float, Dict[str, Any]]]: (æ–‡æ¡£ID, åˆ†æ•°, å…ƒæ•°æ®)
        """
        try:
            logger.info(f"ğŸ” [å‘é‡æ£€ç´¢] ä»“åº“: {repository_identifier} - å¼€å§‹å‘é‡æ£€ç´¢ï¼Œé—®é¢˜é•¿åº¦: {len(question)} å­—ç¬¦")
            
            # åˆ›å»º embedding é…ç½®å¯¹è±¡
            # ç¡®ä¿ extra_params ä¸ä¸º None
            embedding_config_copy = embedding_config.copy()
            if embedding_config_copy.get("extra_params") is None:
                embedding_config_copy["extra_params"] = {}

            embedding_cfg = EmbeddingConfig.from_dict(embedding_config_copy)
            logger.debug(f"ğŸ¤– [æ¨¡å‹é…ç½®] ä»“åº“: {repository_identifier} - ä½¿ç”¨ {embedding_cfg.provider}/{embedding_cfg.model_name} æ¨¡å‹")

            # åŠ è½½ embedding æ¨¡å‹
            logger.debug(f"âš¡ [æ¨¡å‹åŠ è½½] ä»“åº“: {repository_identifier} - æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...")
            embedding_model = EmbeddingManager.get_embedding_model(embedding_cfg)
            logger.debug(f"âœ… [æ¨¡å‹å°±ç»ª] ä»“åº“: {repository_identifier} - Embedding æ¨¡å‹åŠ è½½å®Œæˆ")

            # å‘é‡åŒ–é—®é¢˜
            logger.debug(f"ğŸ§  [é—®é¢˜å‘é‡åŒ–] ä»“åº“: {repository_identifier} - æ­£åœ¨å°†é—®é¢˜è½¬æ¢ä¸ºå‘é‡...")
            question_embedding = embedding_model.embed_query(question)
            logger.debug(f"âœ… [å‘é‡ç”Ÿæˆ] ä»“åº“: {repository_identifier} - é—®é¢˜å‘é‡åŒ–å®Œæˆï¼Œç»´åº¦: {len(question_embedding)}")

            # åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢
            logger.debug(f"ğŸ” [æ•°æ®åº“æ£€ç´¢] ä»“åº“: {repository_identifier} - æ­£åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢ç›¸ä¼¼æ–‡æ¡£...")
            results = get_vector_store().query_repository_collection(
                repository_identifier,
                question_embedding,
                n_results=settings.VECTOR_SEARCH_TOP_K
            )
            logger.debug(f"ğŸ“Š [æ£€ç´¢ç»“æœ] ä»“åº“: {repository_identifier} - å‘é‡æ•°æ®åº“è¿”å›ç»“æœ")            # è½¬æ¢ç»“æœæ ¼å¼
            vector_results = []
            if results["ids"] and results["ids"][0]:
                logger.info(f"âœ… [æ£€ç´¢æˆåŠŸ] ä»“åº“: {repository_identifier} - æ‰¾åˆ° {len(results['ids'][0])} ä¸ªç›¸ä¼¼æ–‡æ¡£")
                for i, doc_id in enumerate(results["ids"][0]):
                    distance = results["distances"][0][i]
                    # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆè·ç¦»è¶Šå°ï¼Œåˆ†æ•°è¶Šé«˜ï¼‰
                    score = 1.0 / (1.0 + distance)
                    metadata = results["metadatas"][0][i]
                    vector_results.append((doc_id, score, metadata))
                    
                    if i < 3:  # åªè®°å½•å‰3ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
                        file_path = metadata.get('file_path', 'unknown')
                        logger.debug(f"ğŸ“„ [ç›¸ä¼¼æ–‡æ¡£] æ’å{i+1}: {file_path}, è·ç¦»: {distance:.4f}, åˆ†æ•°: {score:.4f}")
            else:
                logger.warning(f"âš ï¸ [æ— ç»“æœ] ä»“åº“: {repository_identifier} - å‘é‡æ£€ç´¢æœªæ‰¾åˆ°ç›¸ä¼¼æ–‡æ¡£")

            logger.info(f"ğŸ¯ [å‘é‡æ£€ç´¢å®Œæˆ] ä»“åº“: {repository_identifier} - è¿”å› {len(vector_results)} ä¸ªç»“æœ")
            return vector_results

        except Exception as e:
            logger.error(f"âŒ [å‘é‡æ£€ç´¢å¤±è´¥] ä»“åº“: {repository_identifier} - {str(e)}")
            return []

    def _improved_tokenize(self, text: str) -> List[str]:
        """
        æ”¹è¿›çš„åˆ†è¯æ–¹æ³•ï¼Œèƒ½æ›´å¥½åœ°å¤„ç†æ–‡ä»¶åå’Œä¸­è‹±æ–‡æ··åˆå†…å®¹
        
        Args:
            text: å¾…åˆ†è¯çš„æ–‡æœ¬
            
        Returns:
            List[str]: åˆ†è¯ç»“æœ
        """
        import re
        
        # è½¬æ¢ä¸ºå°å†™
        text = text.lower()
        
        # æå–æ–‡ä»¶åï¼ˆåŒ…å«æ‰©å±•åçš„å®Œæ•´æ–‡ä»¶åï¼‰
        file_pattern = r'[a-zA-Z0-9_-]+\.[a-zA-Z0-9]+'
        file_matches = re.findall(file_pattern, text)
        
        # æå–è·¯å¾„åˆ†éš”ç¬¦åˆ†å‰²çš„éƒ¨åˆ†
        path_pattern = r'[a-zA-Z0-9_-]+(?:/[a-zA-Z0-9_-]+)*'
        path_matches = re.findall(path_pattern, text)
        
        # åŸºæœ¬åˆ†è¯ï¼ˆç©ºæ ¼ã€æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼‰
        basic_tokens = re.findall(r'[a-zA-Z0-9_-]+|[\u4e00-\u9fff]+', text)
        
        # åˆå¹¶æ‰€æœ‰token
        all_tokens = set()
        all_tokens.update(basic_tokens)
        all_tokens.update(file_matches)
        
        # ä¸ºæ–‡ä»¶åæ·»åŠ ä¸å¸¦æ‰©å±•åçš„ç‰ˆæœ¬
        for file_match in file_matches:
            name_without_ext = file_match.split('.')[0]
            all_tokens.add(name_without_ext)
            
        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’Œå•å­—ç¬¦
        tokens = [token for token in all_tokens if len(token) > 1]
        
        return tokens

    def _calculate_file_name_bonus(self, query_tokens: List[str], documents: List[Dict], doc_scores: List[float]) -> List[float]:
        """
        è®¡ç®—æ–‡ä»¶ååŒ¹é…çš„é¢å¤–åŠ åˆ†
        
        Args:
            query_tokens: æŸ¥è¯¢è¯åˆ—è¡¨
            documents: æ–‡æ¡£åˆ—è¡¨
            doc_scores: åŸå§‹BM25åˆ†æ•°
            
        Returns:
            List[float]: æ¯ä¸ªæ–‡æ¡£çš„åŠ åˆ†
        """
        import re
        
        # ä»æŸ¥è¯¢ä¸­æå–å¯èƒ½çš„æ–‡ä»¶å
        file_name_patterns = []
        for token in query_tokens:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶åæ ¼å¼
            if '.' in token and re.match(r'^[a-zA-Z0-9_-]+\.[a-zA-Z0-9]+$', token):
                file_name_patterns.append(token)
                # åŒæ—¶æ·»åŠ ä¸å¸¦æ‰©å±•åçš„ç‰ˆæœ¬
                name_without_ext = token.split('.')[0]
                file_name_patterns.append(name_without_ext)
        
        bonus_scores = [0.0] * len(documents)
        
        if not file_name_patterns:
            return bonus_scores
            
        # ä¸ºæ¯ä¸ªæ–‡æ¡£è®¡ç®—æ–‡ä»¶ååŒ¹é…åŠ åˆ†
        for i, doc in enumerate(documents):
            file_path = doc["metadata"].get("file_path", "")
            if not file_path:
                continue
                
            # æå–æ–‡ä»¶å
            file_name = file_path.split('/')[-1].split('\\')[-1].lower()
            
            # æ£€æŸ¥æ–‡ä»¶ååŒ¹é…
            for pattern in file_name_patterns:
                if pattern.lower() in file_name:
                    # ç²¾ç¡®åŒ¹é…ç»™æ›´é«˜åˆ†æ•°
                    if pattern.lower() == file_name or pattern.lower() == file_name.split('.')[0]:
                        bonus_scores[i] += 10.0  # ç²¾ç¡®åŒ¹é…é«˜åˆ†
                    else:
                        bonus_scores[i] += 5.0   # éƒ¨åˆ†åŒ¹é…ä¸­ç­‰åˆ†
                        
            # æ£€æŸ¥è·¯å¾„åŒ¹é…
            for pattern in file_name_patterns:
                if pattern.lower() in file_path.lower():
                    bonus_scores[i] += 2.0   # è·¯å¾„åŒ¹é…ä½åˆ†
                    
        return bonus_scores

    def _bm25_search(
            self,
            repository_identifier: str,
            question: str
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        BM25 å…³é”®è¯æ£€ç´¢

        Args:
            repository_identifier: ä»“åº“æ ‡è¯†ç¬¦
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            List[Tuple[str, float, Dict[str, Any]]]: (æ–‡æ¡£ID, åˆ†æ•°, å…ƒæ•°æ®)
        """
        try:
            logger.info(f"ğŸ”¤ [BM25æ£€ç´¢] ä»“åº“: {repository_identifier} - å¼€å§‹å…³é”®è¯æ£€ç´¢")
            
            # è·å–æˆ–æ„å»º BM25 ç´¢å¼•
            bm25_index = self._get_bm25_index(repository_identifier)
            if not bm25_index:
                logger.warning(f"âš ï¸ [ç´¢å¼•ç¼ºå¤±] ä»“åº“: {repository_identifier} - BM25ç´¢å¼•ä¸å­˜åœ¨")
                return []

            # æ”¹è¿›çš„åˆ†è¯é€»è¾‘
            query_tokens = self._improved_tokenize(question)
            logger.info(f"ğŸ“ [åˆ†è¯ç»“æœ] ä»“åº“: {repository_identifier} - åŸå§‹é—®é¢˜: '{question}', åˆ†è¯ç»“æœ: {query_tokens}")
            
            # è°ƒè¯•ï¼šæ£€æŸ¥æ–‡æ¡£åˆ†è¯æƒ…å†µ
            documents = self._documents_cache.get(repository_identifier, [])
            if documents and len(documents) > 0:
                sample_doc = documents[0]
                sample_content = sample_doc["metadata"].get("content", sample_doc["content"])
                sample_file_path = sample_doc["metadata"].get("file_path", "")
                sample_combined = f"{sample_content} {sample_file_path}"
                sample_tokens = self._improved_tokenize(sample_combined)
                logger.info(f"ğŸ“„ [æ ·æœ¬æ–‡æ¡£åˆ†è¯] æ–‡ä»¶: {sample_file_path}, åˆ†è¯ç»“æœå‰10ä¸ª: {sample_tokens[:10]}")
                
                # æ£€æŸ¥æŸ¥è¯¢è¯æ˜¯å¦åœ¨æ–‡æ¡£åˆ†è¯ä¸­
                matching_tokens = [token for token in query_tokens if token in sample_tokens]
                logger.info(f"ğŸ” [åŒ¹é…æ£€æŸ¥] æŸ¥è¯¢è¯åœ¨æ ·æœ¬æ–‡æ¡£ä¸­çš„åŒ¹é…: {matching_tokens}")

            # BM25 æœç´¢
            logger.debug(f"ğŸ” [BM25è®¡ç®—] ä»“åº“: {repository_identifier} - æ­£åœ¨è®¡ç®—BM25åˆ†æ•°...")
            doc_scores = bm25_index.get_scores(query_tokens)

            # è·å–æ–‡æ¡£ä¿¡æ¯
            documents = self._documents_cache.get(repository_identifier, [])
            logger.debug(f"ğŸ“š [æ–‡æ¡£ç¼“å­˜] ä»“åº“: {repository_identifier} - ç¼“å­˜ä¸­æœ‰ {len(documents)} ä¸ªæ–‡æ¡£")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶åæŸ¥è¯¢ï¼Œç»™äºˆé¢å¤–åŠ åˆ†
            file_name_bonus = self._calculate_file_name_bonus(query_tokens, documents, doc_scores)
            
            # åº”ç”¨æ–‡ä»¶ååŠ åˆ†
            for i, bonus in enumerate(file_name_bonus):
                if bonus > 0:
                    doc_scores[i] += bonus
                    logger.debug(f"ğŸ“ [æ–‡ä»¶ååŠ åˆ†] æ–‡æ¡£{i}: +{bonus:.4f}")

            # æ’åºå¹¶å–å‰ N ä¸ª
            scored_docs = [
                (documents[i]["id"], score, documents[i]["metadata"])
                for i, score in enumerate(doc_scores)
                if score > 0
            ]
            scored_docs.sort(key=lambda x: x[1], reverse=True)
            
            top_results = scored_docs[:settings.BM25_SEARCH_TOP_K]
            logger.info(f"âœ… [BM25å®Œæˆ] ä»“åº“: {repository_identifier} - æ‰¾åˆ° {len([s for s in doc_scores if s > 0])} ä¸ªåŒ¹é…æ–‡æ¡£ï¼Œè¿”å›å‰ {len(top_results)} ä¸ª")
            
            # è®°å½•å‰å‡ ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
            for i, (doc_id, score, metadata) in enumerate(top_results[:3]):
                file_path = metadata.get('file_path', 'unknown')
                logger.debug(f"ğŸ“„ [BM25ç»“æœ] æ’å{i+1}: {file_path}, BM25åˆ†æ•°: {score:.4f}")

            return top_results

        except Exception as e:
            logger.error(f"âŒ [BM25æ£€ç´¢å¤±è´¥] ä»“åº“: {repository_identifier} - {str(e)}")
            return []

    def _get_bm25_index(self, repository_identifier: str):
        """
        è·å–æˆ–æ„å»º BM25 ç´¢å¼•

        Args:
            repository_identifier: ä»“åº“æ ‡è¯†ç¬¦

        Returns:
            BM25Okapi ç´¢å¼•æˆ– None
        """
        # æ£€æŸ¥ç¼“å­˜
        if repository_identifier in self._bm25_cache:
            return self._bm25_cache[repository_identifier]

        try:
            # è·å–æ‰€æœ‰æ–‡æ¡£ - ä½¿ç”¨åŸºäºä»“åº“çš„æŸ¥è¯¢
            documents = get_vector_store().get_all_documents_from_repository_collection(repository_identifier)
            if not documents:
                return None

            # å‡†å¤‡æ–‡æ¡£æ–‡æœ¬ï¼ˆæ”¹è¿›çš„åˆ†è¯ï¼‰
            doc_texts = []
            for doc in documents:
                # ä½¿ç”¨å…ƒæ•°æ®ä¸­çš„å†…å®¹
                content = doc["metadata"].get("content", doc["content"])
                # æå–æ–‡ä»¶è·¯å¾„ä¿¡æ¯
                file_path = doc["metadata"].get("file_path", "")
                # ç»„åˆå†…å®¹å’Œæ–‡ä»¶è·¯å¾„è¿›è¡Œåˆ†è¯
                combined_content = f"{content} {file_path}"
                doc_texts.append(self._improved_tokenize(combined_content))

            # æ„å»º BM25 ç´¢å¼•
            bm25_index = BM25Okapi(doc_texts)

            # ç¼“å­˜ç´¢å¼•å’Œæ–‡æ¡£
            self._bm25_cache[repository_identifier] = bm25_index
            self._documents_cache[repository_identifier] = documents

            logger.info(f"ä¸ºä»“åº“ {repository_identifier} æ„å»ºäº† BM25 ç´¢å¼•ï¼ŒåŒ…å« {len(documents)} ä¸ªæ–‡æ¡£")
            return bm25_index

        except Exception as e:
            logger.error(f"æ„å»º BM25 ç´¢å¼•å¤±è´¥: {str(e)}")
            return None

    def _reciprocal_rank_fusion(
            self,
            vector_results: List[Tuple[str, float, Dict[str, Any]]],
            bm25_results: List[Tuple[str, float, Dict[str, Any]]],
            k: int = 60
    ) -> List[RetrievedChunk]:
        """
        RRF (Reciprocal Rank Fusion) ç®—æ³•èåˆä¸¤ä¸ªæ£€ç´¢ç»“æœ

        Args:
            vector_results: å‘é‡æ£€ç´¢ç»“æœ
            bm25_results: BM25 æ£€ç´¢ç»“æœ
            k: RRF å‚æ•°

        Returns:
            List[RetrievedChunk]: èåˆåçš„ç»“æœ
        """
        logger.info(f"ğŸ”€ [RRFèåˆ] å¼€å§‹èåˆæ£€ç´¢ç»“æœ - å‘é‡ç»“æœ: {len(vector_results)} ä¸ª, BM25ç»“æœ: {len(bm25_results)} ä¸ª")
        
        # åˆ›å»ºæ–‡æ¡£ ID åˆ°ä¿¡æ¯çš„æ˜ å°„
        doc_info = {}

        # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
        logger.debug(f"ğŸ“Š [å¤„ç†å‘é‡ç»“æœ] æ­£åœ¨å¤„ç† {len(vector_results)} ä¸ªå‘é‡æ£€ç´¢ç»“æœ...")
        for rank, (doc_id, score, metadata) in enumerate(vector_results):
            if doc_id not in doc_info:
                doc_info[doc_id] = {
                    "metadata": metadata,
                    "content": metadata.get("content", ""),
                    "vector_rank": rank + 1,
                    "bm25_rank": None,
                    "rrf_score": 0.0
                }
            rrf_contribution = 1.0 / (k + rank + 1)
            doc_info[doc_id]["rrf_score"] += rrf_contribution
            
            if rank < 3:  # è®°å½•å‰3ä¸ªçš„è¯¦ç»†ä¿¡æ¯
                file_path = metadata.get('file_path', 'unknown')
                logger.debug(f"ğŸ“„ [å‘é‡è´¡çŒ®] {file_path} - æ’å: {rank+1}, RRFè´¡çŒ®: {rrf_contribution:.4f}")

        # å¤„ç† BM25 æ£€ç´¢ç»“æœ
        logger.debug(f"ğŸ“Š [å¤„ç†BM25ç»“æœ] æ­£åœ¨å¤„ç† {len(bm25_results)} ä¸ªBM25æ£€ç´¢ç»“æœ...")
        for rank, (doc_id, score, metadata) in enumerate(bm25_results):
            if doc_id not in doc_info:
                doc_info[doc_id] = {
                    "metadata": metadata,
                    "content": metadata.get("content", ""),
                    "vector_rank": None,
                    "bm25_rank": rank + 1,
                    "rrf_score": 0.0
                }
            else:
                doc_info[doc_id]["bm25_rank"] = rank + 1
            rrf_contribution = 1.0 / (k + rank + 1)
            doc_info[doc_id]["rrf_score"] += rrf_contribution
            
            if rank < 3:  # è®°å½•å‰3ä¸ªçš„è¯¦ç»†ä¿¡æ¯
                file_path = metadata.get('file_path', 'unknown')
                logger.debug(f"ğŸ“„ [BM25è´¡çŒ®] {file_path} - æ’å: {rank+1}, RRFè´¡çŒ®: {rrf_contribution:.4f}")

        # æŒ‰ RRF åˆ†æ•°æ’åº
        logger.debug(f"ğŸ”„ [RRFæ’åº] æ­£åœ¨æŒ‰RRFåˆ†æ•°æ’åº {len(doc_info)} ä¸ªæ–‡æ¡£...")
        sorted_docs = sorted(
            doc_info.items(),
            key=lambda x: x[1]["rrf_score"],
            reverse=True
        )

        # è½¬æ¢ä¸º RetrievedChunk æ ¼å¼
        retrieved_chunks = []
        for i, (doc_id, info) in enumerate(sorted_docs):
            chunk = RetrievedChunk(
                id=doc_id,
                content=info["content"],
                file_path=info["metadata"].get("file_path", ""),
                start_line=info["metadata"].get("start_line"),
                score=info["rrf_score"],
                metadata=info["metadata"]
            )
            retrieved_chunks.append(chunk)
            
            # è®°å½•å‰å‡ ä¸ªæœ€ç»ˆç»“æœçš„è¯¦ç»†ä¿¡æ¯
            if i < 5:
                file_path = info["metadata"].get('file_path', 'unknown')
                vector_rank = info["vector_rank"] or "N/A"
                bm25_rank = info["bm25_rank"] or "N/A"
                logger.debug(f"ğŸ† [æœ€ç»ˆæ’å{i+1}] {file_path} - RRFåˆ†æ•°: {info['rrf_score']:.4f}, å‘é‡æ’å: {vector_rank}, BM25æ’å: {bm25_rank}")

        logger.info(f"âœ… [RRFèåˆå®Œæˆ] èåˆåå…± {len(retrieved_chunks)} ä¸ªç»“æœ")
        return retrieved_chunks

    def _generate_answer(
            self,
            question: str,
            retrieved_chunks: List[RetrievedChunk],
            llm_config: LLMConfigSchema
    ) -> str:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ

        Args:
            question: ç”¨æˆ·é—®é¢˜
            retrieved_chunks: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            llm_config: LLM é…ç½®

        Returns:
            str: ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        try:
            logger.info(f"ğŸ¤– [LLMç”Ÿæˆ] å¼€å§‹ç”Ÿæˆç­”æ¡ˆ - æ¨¡å‹: {llm_config.provider}/{llm_config.model_name}")
            logger.info(f"ğŸ“ [ä¸Šä¸‹æ–‡å‡†å¤‡] ä½¿ç”¨ {len(retrieved_chunks)} ä¸ªæ–‡æ¡£å—ä½œä¸ºä¸Šä¸‹æ–‡")
            
            # åˆ›å»º LLM é…ç½®å¯¹è±¡
            logger.debug(f"âš™ï¸ [LLMé…ç½®] æä¾›å•†: {llm_config.provider}, æ¨¡å‹: {llm_config.model_name}, æ¸©åº¦: {llm_config.temperature}, æœ€å¤§ä»¤ç‰Œ: {llm_config.max_tokens}")
            logger.info(f"ğŸ” [DEBUG] _generate_answer ä¸­çš„ llm_config:")
            logger.info(f"ğŸ” [DEBUG] - llm_config.provider: {llm_config.provider} (type: {type(llm_config.provider)})")
            logger.info(f"ğŸ” [DEBUG] - hasattr(llm_config.provider, 'value'): {hasattr(llm_config.provider, 'value')}")
            
            provider_value = llm_config.provider.value if hasattr(llm_config.provider, 'value') else llm_config.provider
            logger.info(f"ğŸ” [DEBUG] - æœ€ç»ˆä½¿ç”¨çš„ provider å€¼: {provider_value} (type: {type(provider_value)})")
            
            # å¤„ç† extra_paramsï¼Œç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªå­—å…¸
            extra_params = llm_config.extra_params or {}
            logger.info(f"ğŸ” [DEBUG] - extra_params: {extra_params} (type: {type(extra_params)})")
            
            llm_cfg = LLMConfig(
                provider=provider_value,
                model_name=llm_config.model_name,
                api_key=llm_config.api_key,
                api_base=llm_config.api_base,
                api_version=llm_config.api_version,
                deployment_name=llm_config.deployment_name,
                temperature=llm_config.temperature,
                max_tokens=llm_config.max_tokens,
                **extra_params
            )

            # åŠ è½½ LLM æ¨¡å‹
            logger.info(f"ğŸ”§ [æ¨¡å‹åŠ è½½] æ­£åœ¨åŠ è½½LLMæ¨¡å‹...")
            llm = LLMManager.get_llm(llm_cfg)
            logger.info(f"âœ… [æ¨¡å‹å°±ç»ª] LLMæ¨¡å‹åŠ è½½å®Œæˆ")

            # æ„å»º prompt
            logger.info(f"ğŸ“‹ [æ„å»ºPrompt] æ­£åœ¨æ„å»ºä¸Šä¸‹æ–‡å’Œæç¤ºè¯...")
            context = self._build_context(retrieved_chunks)
            prompt = self._build_prompt(question, context)
            
            # è®¡ç®—ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯
            context_chars = len(context)
            prompt_chars = len(prompt)
            logger.info(f"ğŸ“Š [Promptç»Ÿè®¡] ä¸Šä¸‹æ–‡é•¿åº¦: {context_chars} å­—ç¬¦, å®Œæ•´Prompté•¿åº¦: {prompt_chars} å­—ç¬¦")

            # ç”Ÿæˆç­”æ¡ˆ
            logger.info(f"ğŸš€ [å¼€å§‹ç”Ÿæˆ] æ­£åœ¨è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ...")
            response = llm.invoke(prompt)
            logger.info(f"âœ… [ç”Ÿæˆå®Œæˆ] LLMå“åº”å·²æ¥æ”¶")

            # æå–ç­”æ¡ˆæ–‡æœ¬
            if hasattr(response, 'content'):
                answer = response.content
            else:
                answer = str(response)
            
            logger.info(f"ğŸ“¤ [ç­”æ¡ˆè¾“å‡º] ç”Ÿæˆç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")
            return answer

        except Exception as e:
            logger.error(f"âŒ [ç”Ÿæˆå¤±è´¥] LLMç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}")
            return f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {str(e)}"

    def _build_context(self, retrieved_chunks: List[RetrievedChunk]) -> str:
        """
        æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²

        Args:
            retrieved_chunks: æ£€ç´¢åˆ°çš„æ–‡æ¡£å—

        Returns:
            str: æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡
        """
        context_parts = []

        for i, chunk in enumerate(retrieved_chunks):
            context_part = f"[æ–‡æ¡£ {i+1}] æ–‡ä»¶: {chunk.file_path}"
            if chunk.start_line:
                context_part += f" (è¡Œ {chunk.start_line})"
            context_part += f"\n{chunk.content}\n"
            context_parts.append(context_part)

        return "\n".join(context_parts)

    def _build_prompt(self, question: str, context: str) -> str:
        """
        æ„å»º LLM prompt

        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: ä¸Šä¸‹æ–‡

        Returns:
            str: å®Œæ•´çš„ prompt
        """
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„ä»£ç ä»“åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æ ¹æ®ä¸Šè¿°ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚å›ç­”æ—¶è¯·ï¼š
1. æä¾›å‡†ç¡®ã€å…·ä½“çš„ä¿¡æ¯
2. å¼•ç”¨ç›¸å…³çš„æ–‡ä»¶åå’Œè¡Œå·
3. è§£é‡Šä»£ç çš„åŠŸèƒ½å’Œé€»è¾‘
4. å¦‚æœæ¶‰åŠå¤šä¸ªæ–‡ä»¶ï¼Œè¯·è¯´æ˜å®ƒä»¬ä¹‹é—´çš„å…³ç³»

å›ç­”ï¼š"""

        return prompt

    def _log_query(
            self,
            db: Session,
            request: QueryRequest,
            response: QueryResponse,
            retrieved_chunks: List[RetrievedChunk]
    ):
        """
        è®°å½•æŸ¥è¯¢æ—¥å¿—

        Args:
            db: æ•°æ®åº“ä¼šè¯
            request: æŸ¥è¯¢è¯·æ±‚
            response: æŸ¥è¯¢å“åº”
            retrieved_chunks: æ£€ç´¢ç»“æœ
        """
        try:
            query_log = QueryLog(
                session_id=request.session_id,
                question=request.question,
                answer=response.answer,
                retrieved_chunks_count=len(retrieved_chunks),
                generation_mode=request.generation_mode,
                llm_config=request.llm_config.model_dump() if request.llm_config else None,
                retrieval_time=response.retrieval_time,
                generation_time=response.generation_time,
                total_time=response.total_time
            )

            db.add(query_log)
            db.commit()

        except Exception as e:
            logger.error(f"è®°å½•æŸ¥è¯¢æ—¥å¿—å¤±è´¥: {str(e)}")
            db.rollback()


# å…¨å±€æœåŠ¡å®ä¾‹
query_service = QueryService()