from fastapi import APIRouter, HTTPException, BackgroundTasks
from ....schemas.repository import *
import uuid
from ....services.task_queue import task_queue
from ....worker.tasks import process_repository_task
from ....db.session import get_db_session
from ....db.models import AnalysisSession, TaskStatus
from datetime import datetime, timezone
import logging

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/repos",
    tags=["repos"],
    responses={404: {"description": "Not found"}},
)


@router.post("/analyze")
async def analyze(req: RepoAnalyzeRequest):
    """
    åˆ†æä»“åº“
    æ¥æ”¶åŒ…å« embedding_config çš„è¯·æ±‚ï¼Œå¹¶å°†ä»»åŠ¡æ¨é€åˆ° Celery é˜Ÿåˆ—è¿›è¡Œå¼‚æ­¥å¤„ç†
    """
    try:
        logger.info(f"ğŸš€ [APIè¯·æ±‚] æ”¶åˆ°ä»“åº“åˆ†æè¯·æ±‚ - URL: {req.repo_url}")
        logger.info(f"âš™ï¸ [è¯·æ±‚é…ç½®] Embeddingæä¾›å•†: {req.embedding_config.provider}, æ¨¡å‹: {req.embedding_config.model_name}")
        
        # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
        session_id = str(uuid.uuid4())
        logger.info(f"ğŸ†” [ä¼šè¯åˆ›å»º] ç”Ÿæˆä¼šè¯ID: {session_id}")
        
        # åˆ›å»ºæ•°æ®åº“ä¼šè¯è®°å½•
        logger.info(f"ğŸ’¾ [æ•°æ®åº“] æ­£åœ¨åˆ›å»ºä¼šè¯è®°å½•...")
        db = get_db_session()
        try:
            analysis_session = AnalysisSession(
                session_id=session_id,
                repository_url=req.repo_url,
                status=TaskStatus.PENDING,
                embedding_config=req.embedding_config.model_dump(),
                created_at=datetime.now(timezone.utc)
            )
            db.add(analysis_session)
            db.commit()
            logger.info(f"âœ… [æ•°æ®åº“] ä¼šè¯è®°å½•åˆ›å»ºæˆåŠŸ: {session_id}")
        except Exception as e:
            logger.error(f"âŒ [æ•°æ®åº“é”™è¯¯] åˆ›å»ºä¼šè¯è®°å½•å¤±è´¥: {str(e)}")
            db.rollback()
            raise HTTPException(status_code=500, detail="Failed to create session")
        finally:
            if db:
                db.close()
        
        # å°†ä»»åŠ¡æ¨é€åˆ° Celery
        logger.info(f"ğŸ“¤ [ä»»åŠ¡é˜Ÿåˆ—] æ­£åœ¨æ¨é€ä»»åŠ¡åˆ°Celeryé˜Ÿåˆ—...")
        task = process_repository_task.delay(
            repo_url=req.repo_url,
            session_id=session_id,
            embedding_config=req.embedding_config.model_dump()
        )
        logger.info(f"âœ… [ä»»åŠ¡é˜Ÿåˆ—] ä»»åŠ¡æ¨é€æˆåŠŸ - ä»»åŠ¡ID: {task.id}")
        
        response = {
            "session_id": session_id,
            "task_id": task.id,
            "status": "queued",
            "message": "Repository analysis has been queued for processing"
        }
        logger.info(f"ğŸ‰ [APIå“åº”] åˆ†æè¯·æ±‚å¤„ç†å®Œæˆ - ä¼šè¯ID: {session_id}")
        return response
        
    except Exception as e:
        logger.error(f"ğŸ’¥ [APIé”™è¯¯] å¯åŠ¨åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to start analysis: {str(e)}")


@router.get("/status/{session_id}")
async def status(session_id: str):
    """
    è·å–åˆ†æä¼šè¯çŠ¶æ€
    ä»æ•°æ®åº“ä¸­è·å–æŒ‡å®šä¼šè¯çš„çŠ¶æ€ä¿¡æ¯
    """
    try:
        logger.info(f"ğŸ“Š [çŠ¶æ€æŸ¥è¯¢] æ”¶åˆ°çŠ¶æ€æŸ¥è¯¢è¯·æ±‚ - ä¼šè¯ID: {session_id}")
        
        db = get_db_session()
        try:
            logger.debug(f"ğŸ’¾ [æ•°æ®åº“æŸ¥è¯¢] æ­£åœ¨æŸ¥è¯¢ä¼šè¯çŠ¶æ€...")
            session = db.query(AnalysisSession).filter(
                AnalysisSession.session_id == session_id
            ).first()
            
            if not session:
                logger.warning(f"âš ï¸ [ä¼šè¯ä¸å­˜åœ¨] æœªæ‰¾åˆ°ä¼šè¯: {session_id}")
                raise HTTPException(status_code=404, detail="Session not found")
            
            logger.info(f"âœ… [çŠ¶æ€è·å–] ä¼šè¯çŠ¶æ€: {session.status}, ä»“åº“: {session.repository_url}")
            
            response = {
                "session_id": session_id,
                "status": session.status.value if hasattr(session.status, 'value') else session.status,
                "repository_url": session.repository_url,
                "repository_name": session.repository_name,
                "repository_owner": session.repository_owner,
                "total_files": session.total_files,
                "processed_files": session.processed_files,
                "total_chunks": session.total_chunks,
                "indexed_chunks": session.indexed_chunks,
                "created_at": session.created_at.isoformat() if session.created_at else None,
                "started_at": session.started_at.isoformat() if session.started_at else None,
                "completed_at": session.completed_at.isoformat() if session.completed_at else None,
                "error_message": session.error_message
            }
            
            logger.debug(f"ğŸ“ˆ [è¿›åº¦ç»Ÿè®¡] å¤„ç†æ–‡ä»¶: {session.processed_files}/{session.total_files}, ç´¢å¼•å—: {session.indexed_chunks}/{session.total_chunks}")
            return response
            
        finally:
            if db:
                db.close()
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [çŠ¶æ€æŸ¥è¯¢é”™è¯¯] è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to get session status: {str(e)}")

@router.post("/query")
async def query(req: QueryRequest):
    """
    Receive requests containing generation_mode and llm_config, then push to Celery
    for async processing
    """
    logger.info(f"ğŸ” [æŸ¥è¯¢è¯·æ±‚] æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚ - ç›®æ ‡ä¼šè¯: {req.session_id}")
    logger.info(f"â“ [æŸ¥è¯¢å†…å®¹] é—®é¢˜: {req.question[:100]}{'...' if len(req.question) > 100 else ''}")
    logger.info(f"âš™ï¸ [æŸ¥è¯¢é…ç½®] ç”Ÿæˆæ¨¡å¼: {req.generation_mode.value}")
    
    if req.llm_config:
        logger.info(f"ğŸ¤– [LLMé…ç½®] æä¾›å•†: {req.llm_config.provider}, æ¨¡å‹: {req.llm_config.model_name}")
    
    # ç”Ÿæˆå”¯ä¸€çš„session_id
    session_id = str(uuid.uuid4())
    logger.info(f"ğŸ†” [ä»»åŠ¡ä¼šè¯] ç”ŸæˆæŸ¥è¯¢ä»»åŠ¡ä¼šè¯ID: {session_id}")
    
    # å°†ä»»åŠ¡æ¨é€åˆ°Celery
    logger.info(f"ğŸ“¤ [ä»»åŠ¡é˜Ÿåˆ—] æ­£åœ¨æ¨é€æŸ¥è¯¢ä»»åŠ¡åˆ°é˜Ÿåˆ—...")
    task_id = await task_queue.push_query_task(session_id, req)
    logger.info(f"âœ… [ä»»åŠ¡é˜Ÿåˆ—] æŸ¥è¯¢ä»»åŠ¡æ¨é€æˆåŠŸ - ä»»åŠ¡ID: {task_id}")
    
    response = {
        "session_id": session_id,
        "task_id": task_id,
        "status": "queued",
        "message": "Query task has been queued for processing"
    }
    
    logger.info(f"ğŸ‰ [æŸ¥è¯¢å“åº”] æŸ¥è¯¢è¯·æ±‚å¤„ç†å®Œæˆ - ä»»åŠ¡ä¼šè¯ID: {session_id}")
    return response

@router.get("/query/status/{session_id}")
async def query_status(session_id: str):
    """
    Get the status and result of a query task
    """
    try:
        logger.info(f"ğŸ“Š [æŸ¥è¯¢çŠ¶æ€] æ”¶åˆ°æŸ¥è¯¢çŠ¶æ€è¯·æ±‚ - ä»»åŠ¡ä¼šè¯ID: {session_id}")
        
        logger.debug(f"ğŸ” [çŠ¶æ€æ£€æŸ¥] æ­£åœ¨è·å–ä»»åŠ¡çŠ¶æ€...")
        status = await task_queue.get_task_status(session_id)
        result = await task_queue.get_query_result(session_id)
        
        # ä»»åŠ¡è¿˜åœ¨å¤„ç†ä¸­
        if result is None:
            logger.info(f"â³ [å¤„ç†ä¸­] ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­ - çŠ¶æ€: {status}")
            return {
                "session_id": session_id,
                "status": status.lower(),
                "message": "Task is still being processed"
            }
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å¤±è´¥
        if isinstance(result, dict) and result.get("success") == False:
            error_msg = result.get("error", "Unknown error")
            logger.error(f"âŒ [ä»»åŠ¡å¤±è´¥] æŸ¥è¯¢ä»»åŠ¡å¤±è´¥ - é”™è¯¯: {error_msg}")
            return {
                "session_id": session_id,
                "status": "failed",
                "error": error_msg,
                "message": "Task failed to complete"
            }
        
        # ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œè¿”å›QueryResponseç»“æœ
        logger.info(f"âœ… [ä»»åŠ¡å®Œæˆ] æŸ¥è¯¢ä»»åŠ¡æˆåŠŸå®Œæˆ")
        if isinstance(result, dict) and "data" in result:
            logger.debug(f"ğŸ“Š [ç»“æœç»Ÿè®¡] è¿”å›ç»“æœåŒ…å«æŸ¥è¯¢æ•°æ®")
        
        return {
            "session_id": session_id,
            "status": "completed",
            "result": result,  # è¿™é‡ŒåŒ…å«å®Œæ•´çš„QueryResponseæ•°æ®
            "message": "Task completed successfully"
        }
        
    except Exception as e:
        logger.error(f"âŒ [çŠ¶æ€æŸ¥è¯¢é”™è¯¯] è·å–æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error retrieving task status: {str(e)}")

@router.get("/query/result/{session_id}")
async def query_result(session_id: str):
    """
    Get the final result of a completed query task
    """
    try:
        result = await task_queue.get_query_result(session_id)
        
        if result is None:
            raise HTTPException(status_code=404, detail="Task not found or still processing")
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å¤±è´¥
        if isinstance(result, dict) and result.get("success") == False:
            raise HTTPException(
                status_code=400, 
                detail=f"Task failed: {result.get('error', 'Unknown error')}"
            )
        
        # è¿”å›å®Œæ•´çš„QueryResponseç»“æœ
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error retrieving result: {str(e)}")

@router.get("/query/info/{session_id}")
async def query_task_info(session_id: str):
    """
    Get comprehensive task information including status, result, and errors
    """
    try:
        task_info = await task_queue.get_task_info(session_id)
        return task_info
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error retrieving task info: {str(e)}")
